+++
# Project title.
title = "Bite Squad"

# Date this page was created.
date = 2018-12-10T00:00:00

# Project summary to display on homepage.
summary = "App & Website Testing"

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "deep-learning"]`
tags = []

# Optional external URL for project (replaces project detail page).
external_link = ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references 
#   `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides = ""

# Links (optional).
url_pdf = ""
url_slides = ""
url_video = ""
url_code = ""

# Custom links (optional).
#   Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`.
# url_custom = [{icon_pack = "fab", icon="twitter", name="Follow", url = "https://twitter.com/georgecushen"}]

# Featured image
# To use, add an image named `featured.jpg/png` to your project's folder. 
[image]
  # Caption (optional)
  caption = ""
  
  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = "TopLeft"
+++

# App & Website Testing for Food Delivery Startup
\
\
## Challenges:
BiteSquad was about to launch in multiple new locations. Before this big step, the product teams wanted to collect data on the way users perceive the app in comparison to other food delivery apps, gain insights for potential directions, and test some of the new features.
\
\
\
## Process:

### 1. Automated Usability Testing
I designed a remote automated usability test on [usertesting.com](https://www.usertesting.com/dashboard#!/). The goal was to elicit information from users about appeal and user-friendliness of the website in comparison to the competitors; to understand which aspect of the BiteSquad website appeal them the most, and what do they like and not like about the interface?

After answering a set of questions on design, participants have been given three different scenarios and asked to complete certain tasks designed based on the concerns and priorities of the product teams. I also asked them to complete the same tasks on a first-tier competitor’s website. Remote tests have been video recorded. I analyzed the recordings and prepared a list of key points to be shared with my co-researcher and shape the moderated test accordingly. Based on these initial findings, we made some changes on the questions we asked during the moderated usability test.

[bite1]: https://i.ibb.co/sjMjjpW/1.jpg
![bite1]
\

### 2. Moderated Usability Testing
Based on the insights from the product teams and information collected from the automated usability tests, my co-researcher and I, we prepared a combined usability and competitive test on the recently developed version of the app.

Before the usability test, we conducted a pre-test interview with each participant to get details for the persona(s) and gather information on users’ eating and food ordering habits. We started by letting the participants to explore the app and ask them probing questions whenever appropriate. Then, we gave participants certain scenarios and asked to complete specific tasks, such as adding items to the cart, changing item details, and removing items from the cart. 

[bite2]: https://i.ibb.co/xDyKRPc/2.jpg
![bite2]

**One of the Key Insights:** Users find it hard to remove items from the cart.

> "Adding to the cart was quite easy. I went into the cart. Yet it is not immediately clear how to delete [items]. I expect to see an 'x' sign." –Participant #3

> "There should be an option to change the number of items on your cart. Here there is only 'add more items' option." –Participant #2

We asked participants to complete the same tasks on a competitor app. We recorded their completion, mistake, and success rates. We continued to ask them probing questions and encourage them to compare the two apps at every stage.

Following the competitive test, we conducted a post-test interview with each participant and encouraged them for a blue-sky brainstorming to get some insights on their overall experience and their concerns and expectations regarding food delivery apps. 
\
\
\
## Output:
Based on what we had learned along the research, we put together a presentation with two sections. In the first section, we analyzed user pain points and suggested viable design solutions to resolve these issues. In the second section, we translated users’ comments into design ideas and suggested new directions for research and development. We went over the presentation and explained our findings and suggestions to the product teams at our final meeting and we also emailed them the powerpoint as a written guideline.
\
\
\
## Outcome:
This project is still in progress. The product leaders decided to incorporate our suggestions into the new interface they are developing. I can’t wait to see the result and test it again.

[bite3]: https://i.ibb.co/k8hTTwx/BS2.jpg
![bite3]

[bite4]: https://i.ibb.co/5Gjg6vs/BS1.jpg
![bite4]
